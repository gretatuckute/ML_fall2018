{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The purpose of this application is to solve relevant classification and regression problems for the prostate dataset for use in the project in 02450 Intro to Machine Learning\n",
    "\n",
    "Author: Naia Wright\n",
    "\n",
    "Reviewed by:  \n",
    "\n",
    "Last modified: 28/10/18, 09:39\n",
    "\n",
    "#### Change-log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pylab import figure, plot, xlabel, ylabel, legend, ylim, show\n",
    "\n",
    "from matplotlib.pyplot import figure, boxplot, xlabel, ylabel, show\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection, tree\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "from matplotlib.pyplot import figure, plot, subplot, title, xlabel, ylabel, show, clim\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from toolbox_02450 import feature_selector_lr, bmplot\n",
    "import numpy as np\n",
    "\n",
    "from statistics import mean\n",
    "import graphviz\n",
    "from numpy import array\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a method for importing a spread_sheet using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(path, sheet):\n",
    "    \"\"\"\n",
    "    Method for importing data from a spreadsheet.\n",
    "\n",
    "    :param path: full path to the spreadsheet to load\n",
    "    :param sheet: name of the sheet in the workbook that is loaded\n",
    "    :return: pandas dataFrame with imported data\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    out = pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path and sheet name in the prostate workbook\n",
    "#filePath = 'C:/Users/PeterBakke/Documents/git/ML_fall2018/Data/Prostate.xlsx'\n",
    "#filePath = 'C:/Users/Greta/Documents/Github/ML_fall2018/Data/Prostate.xlsx'\n",
    "filePath = 'C:/Users/narisa/Documents/GitHub/ML_fall2018/Data/Prostate.xlsx'\n",
    "sheet = 'Sheet1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prostate data into dataFrame\n",
    "myData = DataLoader(path=filePath, sheet=sheet)\n",
    "\n",
    "# delete irrelevant columns\n",
    "del myData['ID']\n",
    "del myData['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCaVol', 'lWeight', 'Age', 'lBPH', 'SVI', 'lCP', 'Gleason', 'pgg45', 'lPSA']\n",
      "{6: 0, 7: 1, 8: 2, 9: 3}\n"
     ]
    }
   ],
   "source": [
    "# extract class names and encode with integers (dict)\n",
    "\n",
    "classLabels = myData['Gleason'].values.tolist()\n",
    "classNames = sorted(set(classLabels))\n",
    "classDict = dict(zip(classNames, range(4)))\n",
    "\n",
    "#del myData['Gleason']\n",
    "\n",
    "attributeNames = list(myData.columns.values)\n",
    "\n",
    "print(attributeNames)\n",
    "print(classDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vector y, convert to NumPy array\n",
    "y = np.asarray([classDict[value] for value in classLabels])\n",
    "\n",
    "# Convert dataFrame to numpy array\n",
    "X = myData.values\n",
    "\n",
    "# Compute values of N, M and C\n",
    "N = len(y)\n",
    "M = len(attributeNames)\n",
    "C = len(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.64586143 -2.01663373 -1.87210098 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -2.53331785]\n",
      " [-1.9993129  -0.72575948 -0.79198919 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -2.29971238]\n",
      " [-1.58702059 -2.20015441  1.36823439 -1.03002898 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.15615511 -2.29971238]\n",
      " [-2.17817387 -0.8121913  -0.79198919 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -2.29971238]\n",
      " [-0.5105128  -0.46121762 -0.25193329 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -1.83463099]\n",
      " [-2.04670586 -0.93880639 -1.87210098 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -1.49161747]\n",
      " [-0.5226677  -0.3646778   0.01809466  0.35670122 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -1.49161747]\n",
      " [-0.56020767 -0.20984103 -0.79198919  0.99529051 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -1.4141616 ]\n",
      " [-1.81362657 -0.20984103 -2.2771429  -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -1.24618021]\n",
      " [-0.9610521  -0.90192675 -0.11691932 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -1.24618021]\n",
      " [-0.93418834 -0.05819996  0.15310863 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -1.05492666]\n",
      " [-2.30021799 -0.07100389 -0.11691932  0.80827605 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -1.05492666]\n",
      " [ 0.22465908 -1.4220686  -0.11691932 -1.03002898 -0.52565748 -0.30083707\n",
      "   0.34440695  0.20024597 -1.05492666]\n",
      " [ 0.10834583 -1.47986344  0.42313658 -1.03002898 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.69075673 -0.98428221]\n",
      " [-0.12284403 -0.4385849  -0.92700316 -1.03002898 -0.52565748 -0.1807427\n",
      "   0.34440695 -0.69075673 -0.94018137]\n",
      " [ 0.16302259 -1.33245984  0.2881226  -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.89820677]\n",
      " [-1.50573493 -0.26497044  0.8281785   0.79248386 -0.52565748 -0.30083707\n",
      "   0.34440695  0.20024597 -0.87795465]\n",
      " [ 0.80038343  0.04790351  0.2881226  -1.03002898 -0.52565748  0.39606027\n",
      "  -1.04757113 -0.86895727 -0.85816274]\n",
      " [-1.63076627 -0.84767487 -3.08722674 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.80135103]\n",
      " [-0.9958673   0.46089542  0.8281785   1.07937567 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.76543644]\n",
      " [-0.17279428 -0.4917387  -0.65697521 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.73094466]\n",
      " [ 0.60486894 -0.30009502 -0.52196124  0.95226146 -0.52565748  1.09806826\n",
      "   0.34440695 -0.15615511 -0.71419787]\n",
      " [-1.61593366 -0.59376893 -0.65697521 -0.62277959 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.68164068]\n",
      " [ 0.36817665 -0.4161657  -0.11691932  0.23411435 -0.52565748  0.97627438\n",
      "   0.34440695  1.26944921 -0.66580745]\n",
      " [-0.82278841  0.09023368  0.69316453  1.03860789 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.65025697]\n",
      " [ 0.08264956 -1.18343728  0.55815055  0.13839656 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.619965  ]\n",
      " [-0.71399732  0.21283185  0.15310863 -1.03002898 -0.52565748 -0.44509826\n",
      "   0.34440695  1.62585029 -0.59069151]\n",
      " [-1.49290981  0.55616587  0.42313658  1.18900155 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.15615511 -0.57641572]\n",
      " [-0.26415689 -1.17314627  0.42313658  0.08507392 -0.52565748  0.16402005\n",
      "   0.34440695  1.98225137 -0.54854763]\n",
      " [ 0.9037135  -0.59376893  0.15310863 -1.03002898 -0.52565748  1.29311536\n",
      "  -1.04757113 -0.86895727 -0.50834947]\n",
      " [-0.90814498  1.08218997  0.15310863  1.29047369 -0.52565748 -0.44509826\n",
      "  -1.04757113 -0.86895727 -0.48254597]\n",
      " [-0.9958673   0.41177028  0.15310863  1.11160717 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.40942861]\n",
      " [-0.0636628  -1.38806321  0.96319247  0.80827605 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.40942861]\n",
      " [-1.14287478 -0.84767487 -1.33204508 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727 -0.39781765]\n",
      " [-1.15993242 -0.96684975 -0.11691932 -1.03002898 -0.52565748 -0.44509826\n",
      "  -1.04757113 -0.86895727 -0.3750503 ]\n",
      " [-0.03554419  1.15183144  0.01809466  1.43488428 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.69075673 -0.34197776]\n",
      " [ 0.06234256  0.0661392   1.23322042 -0.47126026 -0.52565748  1.32103713\n",
      "   1.73638502 -0.33435565 -0.27937807]\n",
      " [-0.76124438 -2.94238594  0.01809466 -1.03002898 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.33435565 -0.24968869]\n",
      " [ 1.118048    1.07038088  0.55815055  0.8822505   1.90237946  1.44637892\n",
      "   0.34440695  0.37844651 -0.23044356]\n",
      " [-0.47120382 -1.44501572 -1.06201713  0.5790429  -0.52565748  0.01211097\n",
      "   0.34440695 -0.69075673 -0.17513581]\n",
      " [-0.62209987 -1.14254072 -0.52196124 -1.03002898 -0.52565748 -0.86765522\n",
      "   3.1283631   1.98225137 -0.15745387]\n",
      " [ 0.07862666  0.12592138  0.55815055 -1.03002898 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.51255619 -0.14874583]\n",
      " [-0.65481608  0.55616587 -0.25193329  1.11787737 -0.52565748 -0.1807427\n",
      "  -1.04757113 -0.86895727 -0.13158654]\n",
      " [ 0.35951816  0.62873791 -0.38694727 -1.03002898 -0.52565748  0.71191882\n",
      "   0.34440695 -0.65511662 -0.09011178]\n",
      " [ 0.1160991  -0.51489465  0.2881226   1.14240568 -0.52565748 -0.1807427\n",
      "   0.34440695 -0.15615511  0.0377352 ]\n",
      " [ 0.26772493 -0.55400096 -0.38694727  0.35670122 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.33435565  0.06527282]\n",
      " [ 1.17509901  0.85993605  2.04330426  1.23266023  1.90237946  2.03887464\n",
      "   3.1283631   2.69505353  0.07872178]\n",
      " [-0.15936323  0.95303849  0.55815055  1.11787737 -0.52565748 -0.1807427\n",
      "   0.34440695  0.55664705  0.07872178]\n",
      " [ 0.33747937 -0.30718329 -2.81719879 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727  0.09851369]\n",
      " [-0.11017138 -0.14270309  0.8281785   0.8822505  -0.52565748 -0.44509826\n",
      "  -1.04757113 -0.86895727  0.09851369]\n",
      " [-0.22010989  0.85561411  0.55815055 -1.03002898 -0.52565748 -0.86765522\n",
      "   0.34440695  0.91304813  0.1553254 ]\n",
      " [ 0.26448829  1.421615    0.01809466  1.36687051 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727  0.17346783]\n",
      " [-0.71399732  0.0110004   0.01809466  0.96483055 -0.52565748  0.16402005\n",
      "   0.34440695  1.62585029  0.17943223]\n",
      " [ 0.66269388  1.15563954  0.55815055  1.15435171 -0.52565748  1.16912805\n",
      "   0.34440695  0.55664705  0.18535613]\n",
      " [ 1.53819093 -0.26497044 -0.65697521 -1.03002898 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.69075673  0.1970843 ]\n",
      " [-0.07083973  1.52790617  0.2881226   1.40088236 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.33435565  0.2086566 ]\n",
      " [-0.32020395 -1.79233616 -2.2771429  -1.03002898 -0.52565748  0.48894996\n",
      "   0.34440695 -0.72639684  0.26969337]\n",
      " [-0.75586358  0.31848951 -2.00711495  0.91647239 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727  0.27503575]\n",
      " [-0.68883756  1.2888009   0.8281785   0.23411435 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.15615511  0.28562317]\n",
      " [-0.24626419  0.52151525 -0.38694727  0.82752319 -0.52565748 -0.86765522\n",
      "   0.34440695  0.55664705  0.29086898]\n",
      " [-0.76124438  2.10127925  1.23322042  1.54225202 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727  0.31663434]\n",
      " [ 0.55214455  0.21283185 -0.11691932  1.05246539  1.90237946  1.50170584\n",
      "   0.34440695  0.55664705  0.32673071]\n",
      " [ 1.2159132  -0.2441444   1.09820645 -1.03002898 -0.52565748  1.24908762\n",
      "   3.1283631   2.51685299  0.32673071]\n",
      " [ 0.58394572  0.67590387  0.2881226   1.32186427  1.90237946  1.64596703\n",
      "   0.34440695  1.26944921  0.35147113]\n",
      " [ 0.61675184 -0.01392703  0.01809466 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727  0.35147113]\n",
      " [ 0.09262458  0.48634373 -0.38694727  0.84625007 -0.52565748 -0.1807427\n",
      "   0.34440695 -0.15615511  0.35633597]\n",
      " [ 0.57385266  0.58546452  0.55815055  1.16609525 -0.52565748  1.07914887\n",
      "   0.34440695  1.62585029  0.38496775]\n",
      " [ 0.72349772  0.99008707  1.09820645  1.52927559 -0.52565748 -0.1807427\n",
      "   0.34440695 -0.51255619  0.42173538]\n",
      " [-1.53197866  1.82921036  0.69316453 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727  0.42173538]\n",
      " [-0.1331195   2.70166094  1.09820645  1.54225202 -0.52565748 -0.44509826\n",
      "   0.34440695 -0.69075673  0.43068977]\n",
      " [ 0.43842708 -0.08387821 -0.52196124 -1.03002898  1.90237946  1.07914887\n",
      "   0.34440695  1.26944921  0.46561391]\n",
      " [-0.16203258 -0.67539077  1.77327632  1.14240568 -0.52565748 -0.86765522\n",
      "   0.34440695  0.02204543  0.48675094]\n",
      " [-0.11521787  0.46089542  0.69316453 -1.03002898  1.90237946  0.28936185\n",
      "   0.34440695 -0.15615511  0.50329884]\n",
      " [ 0.41700419 -0.92029384 -0.52196124  0.23411435  1.90237946  0.97627438\n",
      "   3.1283631   2.33865245  0.51953812]\n",
      " [ 1.40654082  0.51652225  0.69316453 -1.03002898  1.90237946  1.50170584\n",
      "   0.34440695 -0.15615511  0.69391731]\n",
      " [ 1.52756447 -0.85663082  0.55815055 -0.1050703   1.90237946  1.8689359\n",
      "   0.34440695  0.91304813  0.74816076]\n",
      " [ 0.56363872  1.88843646  1.09820645  1.40088236 -0.52565748  0.48894996\n",
      "   0.34440695  1.26944921  0.79630031]\n",
      " [ 1.01288993  1.70306453  1.90829029  1.54225202 -0.52565748 -0.86765522\n",
      "   0.34440695 -0.51255619  0.83354436]\n",
      " [ 1.10725223 -0.10984037  0.69316453 -1.03002898  1.90237946  1.98656829\n",
      "   0.34440695  1.62585029  0.85295798]\n",
      " [ 1.2190955   0.45577338 -0.11691932 -1.03002898 -0.52565748  0.39606027\n",
      "   0.34440695  0.91304813  0.90097779]\n",
      " [ 0.10052143 -1.31058265  0.2881226   0.31819952 -0.52565748  0.28936185\n",
      "   0.34440695  0.55664705  0.90356948]\n",
      " [ 0.99242046 -0.3646778  -0.92700316  0.23411435 -0.52565748  1.80201365\n",
      "   0.34440695  1.26944921  0.91641341]\n",
      " [ 1.077152    0.60960358  1.77327632 -0.43510323  1.90237946  0.5312501\n",
      "   0.34440695  0.20024597  0.94648734]\n",
      " [ 1.132233    0.49140008  0.15310863  0.7030969  -0.52565748  1.38643629\n",
      "   3.1283631   1.62585029  0.95140024]\n",
      " [ 0.18109221  0.1899692  -0.52196124  1.10527971 -0.52565748  0.71191882\n",
      "   0.34440695  0.20024597  0.96597463]\n",
      " [ 1.66548696 -0.25800887  0.01809466 -1.03002898  1.90237946  1.80201365\n",
      "   0.34440695  1.26944921  1.00368795]\n",
      " [ 0.57498003  0.24110046 -0.79198919  1.06605117 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727  1.04644915]\n",
      " [ 0.32548825 -0.60986946 -0.25193329 -1.03002898  1.90237946  0.34468877\n",
      "   0.34440695  0.20024597  1.07454209]\n",
      " [ 1.24310643  2.55541174  0.15310863 -1.03002898  1.90237946  1.90019713\n",
      "   0.34440695  1.26944921  1.31139383]\n",
      " [ 0.18109221  0.15525053  1.63826234  0.5790429   1.90237946  0.71191882\n",
      "   0.34440695  1.80405083  1.31945687]\n",
      " [ 1.61742159  1.10952004  0.55815055 -1.03002898 -0.52565748 -0.86765522\n",
      "  -1.04757113 -0.86895727  1.3509826 ]\n",
      " [ 1.00883515  0.11408648 -0.38694727  0.86448408  1.90237946 -0.86765522\n",
      "   0.34440695 -0.33435565  1.43784081]\n",
      " [ 1.26244405  0.58060761  0.55815055 -1.03002898  1.90237946  1.07914887\n",
      "   0.34440695  1.26944921  1.66041493]\n",
      " [ 2.10739693  0.62873791 -2.68218482 -1.03002898  1.90237946  1.68826718\n",
      "   0.34440695  0.55664705  1.92104373]\n",
      " [ 1.3282669  -0.54612667 -1.60207303 -1.03002898  1.90237946  1.90019713\n",
      "   0.34440695 -0.51255619  2.32046525]\n",
      " [ 1.30704467  0.34014146  0.55815055  1.0100326   1.90237946  1.24908762\n",
      "   0.34440695  1.98225137  2.61164875]\n",
      " [ 1.80971922  0.81196061  0.55815055  0.23411435  1.90237946  2.21673517\n",
      "   0.34440695 -0.15615511  2.70345173]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data with mean and std\n",
    "Y = (X - np.ones((N,1))*X.mean(axis=0)) / X.std(axis=0)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.64586143 -2.01663373 -1.87210098 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -2.53331785]\n",
      " [-1.9993129  -0.72575948 -0.79198919 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -2.29971238]\n",
      " [-1.58702059 -2.20015441  1.36823439 -1.03002898 -0.86765522  0.34440695\n",
      "  -0.15615511 -2.29971238]\n",
      " [-2.17817387 -0.8121913  -0.79198919 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -2.29971238]\n",
      " [-0.5105128  -0.46121762 -0.25193329 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.83463099]\n",
      " [-2.04670586 -0.93880639 -1.87210098 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.49161747]\n",
      " [-0.5226677  -0.3646778   0.01809466  0.35670122 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.49161747]\n",
      " [-0.56020767 -0.20984103 -0.79198919  0.99529051 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.4141616 ]\n",
      " [-1.81362657 -0.20984103 -2.2771429  -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.24618021]\n",
      " [-0.9610521  -0.90192675 -0.11691932 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.24618021]\n",
      " [-0.93418834 -0.05819996  0.15310863 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.05492666]\n",
      " [-2.30021799 -0.07100389 -0.11691932  0.80827605 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.05492666]\n",
      " [ 0.22465908 -1.4220686  -0.11691932 -1.03002898 -0.30083707  0.34440695\n",
      "   0.20024597 -1.05492666]\n",
      " [ 0.10834583 -1.47986344  0.42313658 -1.03002898 -0.86765522  0.34440695\n",
      "  -0.69075673 -0.98428221]\n",
      " [-0.12284403 -0.4385849  -0.92700316 -1.03002898 -0.1807427   0.34440695\n",
      "  -0.69075673 -0.94018137]\n",
      " [ 0.16302259 -1.33245984  0.2881226  -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.89820677]\n",
      " [-1.50573493 -0.26497044  0.8281785   0.79248386 -0.30083707  0.34440695\n",
      "   0.20024597 -0.87795465]\n",
      " [ 0.80038343  0.04790351  0.2881226  -1.03002898  0.39606027 -1.04757113\n",
      "  -0.86895727 -0.85816274]\n",
      " [-1.63076627 -0.84767487 -3.08722674 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.80135103]\n",
      " [-0.9958673   0.46089542  0.8281785   1.07937567 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.76543644]\n",
      " [-0.17279428 -0.4917387  -0.65697521 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.73094466]\n",
      " [ 0.60486894 -0.30009502 -0.52196124  0.95226146  1.09806826  0.34440695\n",
      "  -0.15615511 -0.71419787]\n",
      " [-1.61593366 -0.59376893 -0.65697521 -0.62277959 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.68164068]\n",
      " [ 0.36817665 -0.4161657  -0.11691932  0.23411435  0.97627438  0.34440695\n",
      "   1.26944921 -0.66580745]\n",
      " [-0.82278841  0.09023368  0.69316453  1.03860789 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.65025697]\n",
      " [ 0.08264956 -1.18343728  0.55815055  0.13839656 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.619965  ]\n",
      " [-0.71399732  0.21283185  0.15310863 -1.03002898 -0.44509826  0.34440695\n",
      "   1.62585029 -0.59069151]\n",
      " [-1.49290981  0.55616587  0.42313658  1.18900155 -0.86765522  0.34440695\n",
      "  -0.15615511 -0.57641572]\n",
      " [-0.26415689 -1.17314627  0.42313658  0.08507392  0.16402005  0.34440695\n",
      "   1.98225137 -0.54854763]\n",
      " [ 0.9037135  -0.59376893  0.15310863 -1.03002898  1.29311536 -1.04757113\n",
      "  -0.86895727 -0.50834947]\n",
      " [-0.90814498  1.08218997  0.15310863  1.29047369 -0.44509826 -1.04757113\n",
      "  -0.86895727 -0.48254597]\n",
      " [-0.9958673   0.41177028  0.15310863  1.11160717 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.40942861]\n",
      " [-0.0636628  -1.38806321  0.96319247  0.80827605 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.40942861]\n",
      " [-1.14287478 -0.84767487 -1.33204508 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.39781765]\n",
      " [-1.15993242 -0.96684975 -0.11691932 -1.03002898 -0.44509826 -1.04757113\n",
      "  -0.86895727 -0.3750503 ]\n",
      " [-0.03554419  1.15183144  0.01809466  1.43488428 -0.86765522  0.34440695\n",
      "  -0.69075673 -0.34197776]\n",
      " [ 0.06234256  0.0661392   1.23322042 -0.47126026  1.32103713  1.73638502\n",
      "  -0.33435565 -0.27937807]\n",
      " [-0.76124438 -2.94238594  0.01809466 -1.03002898 -0.86765522  0.34440695\n",
      "  -0.33435565 -0.24968869]\n",
      " [ 1.118048    1.07038088  0.55815055  0.8822505   1.44637892  0.34440695\n",
      "   0.37844651 -0.23044356]\n",
      " [-0.47120382 -1.44501572 -1.06201713  0.5790429   0.01211097  0.34440695\n",
      "  -0.69075673 -0.17513581]\n",
      " [-0.62209987 -1.14254072 -0.52196124 -1.03002898 -0.86765522  3.1283631\n",
      "   1.98225137 -0.15745387]\n",
      " [ 0.07862666  0.12592138  0.55815055 -1.03002898 -0.86765522  0.34440695\n",
      "  -0.51255619 -0.14874583]\n",
      " [-0.65481608  0.55616587 -0.25193329  1.11787737 -0.1807427  -1.04757113\n",
      "  -0.86895727 -0.13158654]\n",
      " [ 0.35951816  0.62873791 -0.38694727 -1.03002898  0.71191882  0.34440695\n",
      "  -0.65511662 -0.09011178]\n",
      " [ 0.1160991  -0.51489465  0.2881226   1.14240568 -0.1807427   0.34440695\n",
      "  -0.15615511  0.0377352 ]\n",
      " [ 0.26772493 -0.55400096 -0.38694727  0.35670122 -0.86765522  0.34440695\n",
      "  -0.33435565  0.06527282]\n",
      " [ 1.17509901  0.85993605  2.04330426  1.23266023  2.03887464  3.1283631\n",
      "   2.69505353  0.07872178]\n",
      " [-0.15936323  0.95303849  0.55815055  1.11787737 -0.1807427   0.34440695\n",
      "   0.55664705  0.07872178]\n",
      " [ 0.33747937 -0.30718329 -2.81719879 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.09851369]\n",
      " [-0.11017138 -0.14270309  0.8281785   0.8822505  -0.44509826 -1.04757113\n",
      "  -0.86895727  0.09851369]\n",
      " [-0.22010989  0.85561411  0.55815055 -1.03002898 -0.86765522  0.34440695\n",
      "   0.91304813  0.1553254 ]\n",
      " [ 0.26448829  1.421615    0.01809466  1.36687051 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.17346783]\n",
      " [-0.71399732  0.0110004   0.01809466  0.96483055  0.16402005  0.34440695\n",
      "   1.62585029  0.17943223]\n",
      " [ 0.66269388  1.15563954  0.55815055  1.15435171  1.16912805  0.34440695\n",
      "   0.55664705  0.18535613]\n",
      " [ 1.53819093 -0.26497044 -0.65697521 -1.03002898 -0.86765522  0.34440695\n",
      "  -0.69075673  0.1970843 ]\n",
      " [-0.07083973  1.52790617  0.2881226   1.40088236 -0.86765522  0.34440695\n",
      "  -0.33435565  0.2086566 ]\n",
      " [-0.32020395 -1.79233616 -2.2771429  -1.03002898  0.48894996  0.34440695\n",
      "  -0.72639684  0.26969337]\n",
      " [-0.75586358  0.31848951 -2.00711495  0.91647239 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.27503575]\n",
      " [-0.68883756  1.2888009   0.8281785   0.23411435 -0.86765522  0.34440695\n",
      "  -0.15615511  0.28562317]\n",
      " [-0.24626419  0.52151525 -0.38694727  0.82752319 -0.86765522  0.34440695\n",
      "   0.55664705  0.29086898]\n",
      " [-0.76124438  2.10127925  1.23322042  1.54225202 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.31663434]\n",
      " [ 0.55214455  0.21283185 -0.11691932  1.05246539  1.50170584  0.34440695\n",
      "   0.55664705  0.32673071]\n",
      " [ 1.2159132  -0.2441444   1.09820645 -1.03002898  1.24908762  3.1283631\n",
      "   2.51685299  0.32673071]\n",
      " [ 0.58394572  0.67590387  0.2881226   1.32186427  1.64596703  0.34440695\n",
      "   1.26944921  0.35147113]\n",
      " [ 0.61675184 -0.01392703  0.01809466 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.35147113]\n",
      " [ 0.09262458  0.48634373 -0.38694727  0.84625007 -0.1807427   0.34440695\n",
      "  -0.15615511  0.35633597]\n",
      " [ 0.57385266  0.58546452  0.55815055  1.16609525  1.07914887  0.34440695\n",
      "   1.62585029  0.38496775]\n",
      " [ 0.72349772  0.99008707  1.09820645  1.52927559 -0.1807427   0.34440695\n",
      "  -0.51255619  0.42173538]\n",
      " [-1.53197866  1.82921036  0.69316453 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.42173538]\n",
      " [-0.1331195   2.70166094  1.09820645  1.54225202 -0.44509826  0.34440695\n",
      "  -0.69075673  0.43068977]\n",
      " [ 0.43842708 -0.08387821 -0.52196124 -1.03002898  1.07914887  0.34440695\n",
      "   1.26944921  0.46561391]\n",
      " [-0.16203258 -0.67539077  1.77327632  1.14240568 -0.86765522  0.34440695\n",
      "   0.02204543  0.48675094]\n",
      " [-0.11521787  0.46089542  0.69316453 -1.03002898  0.28936185  0.34440695\n",
      "  -0.15615511  0.50329884]\n",
      " [ 0.41700419 -0.92029384 -0.52196124  0.23411435  0.97627438  3.1283631\n",
      "   2.33865245  0.51953812]\n",
      " [ 1.40654082  0.51652225  0.69316453 -1.03002898  1.50170584  0.34440695\n",
      "  -0.15615511  0.69391731]\n",
      " [ 1.52756447 -0.85663082  0.55815055 -0.1050703   1.8689359   0.34440695\n",
      "   0.91304813  0.74816076]\n",
      " [ 0.56363872  1.88843646  1.09820645  1.40088236  0.48894996  0.34440695\n",
      "   1.26944921  0.79630031]\n",
      " [ 1.01288993  1.70306453  1.90829029  1.54225202 -0.86765522  0.34440695\n",
      "  -0.51255619  0.83354436]\n",
      " [ 1.10725223 -0.10984037  0.69316453 -1.03002898  1.98656829  0.34440695\n",
      "   1.62585029  0.85295798]\n",
      " [ 1.2190955   0.45577338 -0.11691932 -1.03002898  0.39606027  0.34440695\n",
      "   0.91304813  0.90097779]\n",
      " [ 0.10052143 -1.31058265  0.2881226   0.31819952  0.28936185  0.34440695\n",
      "   0.55664705  0.90356948]\n",
      " [ 0.99242046 -0.3646778  -0.92700316  0.23411435  1.80201365  0.34440695\n",
      "   1.26944921  0.91641341]\n",
      " [ 1.077152    0.60960358  1.77327632 -0.43510323  0.5312501   0.34440695\n",
      "   0.20024597  0.94648734]\n",
      " [ 1.132233    0.49140008  0.15310863  0.7030969   1.38643629  3.1283631\n",
      "   1.62585029  0.95140024]\n",
      " [ 0.18109221  0.1899692  -0.52196124  1.10527971  0.71191882  0.34440695\n",
      "   0.20024597  0.96597463]\n",
      " [ 1.66548696 -0.25800887  0.01809466 -1.03002898  1.80201365  0.34440695\n",
      "   1.26944921  1.00368795]\n",
      " [ 0.57498003  0.24110046 -0.79198919  1.06605117 -0.86765522 -1.04757113\n",
      "  -0.86895727  1.04644915]\n",
      " [ 0.32548825 -0.60986946 -0.25193329 -1.03002898  0.34468877  0.34440695\n",
      "   0.20024597  1.07454209]\n",
      " [ 1.24310643  2.55541174  0.15310863 -1.03002898  1.90019713  0.34440695\n",
      "   1.26944921  1.31139383]\n",
      " [ 0.18109221  0.15525053  1.63826234  0.5790429   0.71191882  0.34440695\n",
      "   1.80405083  1.31945687]\n",
      " [ 1.61742159  1.10952004  0.55815055 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727  1.3509826 ]\n",
      " [ 1.00883515  0.11408648 -0.38694727  0.86448408 -0.86765522  0.34440695\n",
      "  -0.33435565  1.43784081]\n",
      " [ 1.26244405  0.58060761  0.55815055 -1.03002898  1.07914887  0.34440695\n",
      "   1.26944921  1.66041493]\n",
      " [ 2.10739693  0.62873791 -2.68218482 -1.03002898  1.68826718  0.34440695\n",
      "   0.55664705  1.92104373]\n",
      " [ 1.3282669  -0.54612667 -1.60207303 -1.03002898  1.90019713  0.34440695\n",
      "  -0.51255619  2.32046525]\n",
      " [ 1.30704467  0.34014146  0.55815055  1.0100326   1.24908762  0.34440695\n",
      "   1.98225137  2.61164875]\n",
      " [ 1.80971922  0.81196061  0.55815055  0.23411435  2.21673517  0.34440695\n",
      "  -0.15615511  2.70345173]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1.]\n",
      "['lCaVol' 'lWeight' 'Age' 'lBPH' 'lCP' 'Gleason' 'pgg45' 'lPSA']\n"
     ]
    }
   ],
   "source": [
    "# Remove attribute 5 (SVI) from X\n",
    "X_classification = Y[:,[0,1,2,3,5,6,7,8]]\n",
    "print(X_classification)\n",
    "# Use attribute 5 (SVI) as y\n",
    "y_classification = X[:,4]\n",
    "print(y_classification)\n",
    "# Remove attribute 5 (SVI) from attribute names\n",
    "\n",
    "attributeNames_classification = np.array(attributeNames)[[0, 1, 2, 3, 5, 6, 7, 8]]\n",
    "print(attributeNames_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for KNN - Naia 2018-11-03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[24.833333333333336, 22.083333333333336, 18.333333333333336, 20.833333333333336, 19.583333333333336, 18.25, 17.0, 18.25, 15.583333333333334, 14.416666666666668, 14.416666666666668, 18.25, 14.333333333333334, 18.25, 17.0, 19.583333333333332, 20.833333333333332, 22.083333333333332, 22.083333333333332, 22.083333333333332, 22.083333333333332, 22.083333333333332, 22.083333333333332, 22.083333333333332, 22.083333333333332, 24.666666666666668, 24.666666666666668, 24.666666666666668, 23.416666666666668, 24.666666666666668, 24.666666666666668, 24.666666666666668, 24.666666666666668, 23.333333333333332, 23.333333333333332, 23.333333333333332, 23.333333333333332, 23.333333333333332, 23.333333333333332, 23.333333333333332]\n",
      "The index of optimal KNN value is: 12\n",
      "The optimal KNN value across inner CV folds is: 13\n",
      "Errors for each outer CV fold: [0.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[15.833333333333334, 18.25, 11.833333333333334, 13.166666666666668, 10.5, 11.833333333333334, 9.166666666666666, 11.833333333333334, 10.5, 13.166666666666666, 11.833333333333334, 13.166666666666666, 13.166666666666666, 13.166666666666666, 11.833333333333334, 14.5, 11.833333333333334, 15.833333333333334, 15.833333333333334, 17.083333333333336, 17.083333333333336, 15.75, 15.75, 21.083333333333332, 19.75, 21.0, 19.666666666666668, 22.25, 22.25, 24.833333333333336, 24.833333333333336, 24.833333333333336, 24.833333333333336, 24.833333333333336, 24.833333333333336, 24.833333333333336, 24.833333333333336, 24.833333333333336, 24.833333333333336, 24.833333333333336]\n",
      "The index of optimal KNN value is: 6\n",
      "The optimal KNN value across inner CV folds is: 7\n",
      "Errors for each outer CV fold: [0.0, 15.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[25.583333333333336, 21.75, 18.083333333333336, 19.333333333333332, 16.916666666666668, 16.666666666666668, 11.583333333333334, 12.833333333333334, 12.833333333333334, 16.75, 15.416666666666666, 16.75, 16.75, 18.0, 15.416666666666666, 15.416666666666666, 14.083333333333334, 16.666666666666668, 14.166666666666666, 15.333333333333334, 18.0, 20.416666666666668, 20.416666666666668, 21.666666666666668, 21.666666666666668, 23.0, 23.0, 23.0, 23.0, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668]\n",
      "The index of optimal KNN value is: 6\n",
      "The optimal KNN value across inner CV folds is: 7\n",
      "Errors for each outer CV fold: [0.0, 15.0, 5.2631578947368425]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[17.75, 15.333333333333334, 13.75, 12.75, 17.666666666666668, 14.0, 15.166666666666666, 15.25, 13.916666666666666, 14.0, 14.0, 15.25, 15.25, 16.666666666666668, 14.083333333333334, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666, 15.416666666666666]\n",
      "The index of optimal KNN value is: 3\n",
      "The optimal KNN value across inner CV folds is: 4\n",
      "Errors for each outer CV fold: [0.0, 15.0, 5.2631578947368425, 10.526315789473685]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[16.5, 8.75, 7.5, 7.5, 8.833333333333334, 8.833333333333334, 7.583333333333333, 7.583333333333333, 7.583333333333333, 8.916666666666666, 8.916666666666666, 8.916666666666666, 8.916666666666666, 11.5, 11.5, 11.5, 10.25, 10.25, 10.25, 16.583333333333332, 12.75, 15.25, 15.25, 19.166666666666668, 19.166666666666668, 19.083333333333332, 20.333333333333332, 21.666666666666668, 20.333333333333332, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0]\n",
      "The index of optimal KNN value is: 2\n",
      "The optimal KNN value across inner CV folds is: 3\n",
      "Errors for each outer CV fold: [0.0, 15.0, 5.2631578947368425, 10.526315789473685, 31.57894736842105]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "K_KNN = range(1,41) # Change here for different nearest neighbour crossvalidation - test of K=1-40\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner['K_KNN_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=2 #euclidean_distance\n",
    "                       \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['K_KNN_of_{0}'.format(value)].append(errorKNN_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_K = K_KNN[top_count]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifierOuter.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n",
    "error_KNN = error_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[13.166666666666668, 7.833333333333334, 13.083333333333334, 11.75, 9.166666666666668, 10.416666666666668, 10.416666666666668, 13.0, 11.75, 11.666666666666668, 12.916666666666668, 12.916666666666668, 13.0, 10.416666666666668, 10.416666666666668, 13.0, 13.083333333333334, 14.333333333333334, 13.0]\n",
      "The index of optimal tc value is: 1\n",
      "The optimal tc value across inner CV folds is: 3\n",
      "Errors for each outer tc fold: [20.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[14.333333333333334, 11.75, 14.416666666666668, 15.75, 14.416666666666668, 15.75, 14.416666666666668, 15.75, 15.75, 14.416666666666668, 14.416666666666668, 17.083333333333336, 15.75, 17.083333333333336, 18.333333333333336, 14.416666666666668, 14.416666666666668, 17.083333333333336, 14.416666666666668]\n",
      "The index of optimal tc value is: 1\n",
      "The optimal tc value across inner CV folds is: 3\n",
      "Errors for each outer tc fold: [20.0, 10.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[15.25, 11.5, 15.25, 14.0, 15.333333333333334, 14.083333333333334, 15.25, 11.5, 14.0, 16.5, 14.0, 12.833333333333334, 19.166666666666668, 12.75, 15.333333333333334, 11.5, 11.5, 17.916666666666668, 14.083333333333334]\n",
      "The index of optimal tc value is: 1\n",
      "The optimal tc value across inner CV folds is: 3\n",
      "Errors for each outer tc fold: [20.0, 10.0, 5.2631578947368425]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[15.333333333333334, 16.583333333333332, 15.25, 15.25, 14.0, 15.25, 15.25, 14.0, 15.25, 12.75, 14.0, 14.0, 12.75, 14.0, 14.0, 14.0, 15.25, 15.25, 15.25]\n",
      "The index of optimal tc value is: 9\n",
      "The optimal tc value across inner CV folds is: 11\n",
      "Errors for each outer tc fold: [20.0, 10.0, 5.2631578947368425, 21.05263157894737]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[16.666666666666668, 15.416666666666666, 21.75, 21.666666666666668, 19.166666666666668, 19.25, 20.416666666666668, 17.916666666666668, 20.5, 21.666666666666668, 19.166666666666668, 19.166666666666668, 19.25, 20.5, 17.833333333333332, 20.416666666666668, 17.916666666666668, 19.166666666666668, 19.083333333333332]\n",
      "The index of optimal tc value is: 1\n",
      "The optimal tc value across inner CV folds is: 3\n",
      "Errors for each outer tc fold: [20.0, 10.0, 5.2631578947368425, 21.05263157894737, 15.789473684210526]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for decision trees\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "# Tree complexity parameter - constraint on maximum depth\n",
    "tc = np.arange(2, 21, 1)\n",
    "print(tc)\n",
    "\n",
    "\n",
    "for count, value in enumerate(tc):\n",
    "    error_inner['tc_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(tc):\n",
    "            dist=1\n",
    "            \n",
    "            # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "            dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=value) \n",
    "            dtc.fit(X_train_inner, y_train_inner.ravel());\n",
    "            classifier_lst.append(dtc)\n",
    "            \n",
    "            y_dtc = dtc.predict(X_test_inner);\n",
    "            errordtc_inner = 100*(y_dtc!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['tc_of_{0}'.format(value)].append(errordtc_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal tc value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_tc = tc[top_count]\n",
    "    \n",
    "    print('The optimal tc value across inner CV folds is: ' + str(optimal_tc))\n",
    "    \n",
    "    \n",
    "    dtcclassifierOuter = tree.DecisionTreeClassifier(criterion='gini', max_depth=optimal_tc);  #Uses optimal_tc, which was found in the inner CV loop\n",
    "    dtcclassifierOuter.fit(X_train_outer, y_train_outer.ravel());\n",
    "            \n",
    "    y_dtc_outer = dtcclassifierOuter.predict(X_test_outer);\n",
    "    errordtc_outer = 100*(y_dtc_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errordtc_outer)\n",
    "    print('Errors for each outer tc fold: ' + str(error_outer))\n",
    "\n",
    "error_dct = error_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "[[-1.64586143 -2.01663373 -1.87210098 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -2.53331785]\n",
      " [-1.9993129  -0.72575948 -0.79198919 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -2.29971238]\n",
      " [-2.17817387 -0.8121913  -0.79198919 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -2.29971238]\n",
      " [-2.04670586 -0.93880639 -1.87210098 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.49161747]\n",
      " [-0.56020767 -0.20984103 -0.79198919  0.99529051 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.4141616 ]\n",
      " [-0.9610521  -0.90192675 -0.11691932 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.24618021]\n",
      " [-0.93418834 -0.05819996  0.15310863 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.05492666]\n",
      " [-2.30021799 -0.07100389 -0.11691932  0.80827605 -0.86765522 -1.04757113\n",
      "  -0.86895727 -1.05492666]\n",
      " [ 0.22465908 -1.4220686  -0.11691932 -1.03002898 -0.30083707  0.34440695\n",
      "   0.20024597 -1.05492666]\n",
      " [ 0.16302259 -1.33245984  0.2881226  -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.89820677]\n",
      " [ 0.80038343  0.04790351  0.2881226  -1.03002898  0.39606027 -1.04757113\n",
      "  -0.86895727 -0.85816274]\n",
      " [-0.9958673   0.46089542  0.8281785   1.07937567 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.76543644]\n",
      " [-0.17279428 -0.4917387  -0.65697521 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.73094466]\n",
      " [ 0.36817665 -0.4161657  -0.11691932  0.23411435  0.97627438  0.34440695\n",
      "   1.26944921 -0.66580745]\n",
      " [-0.82278841  0.09023368  0.69316453  1.03860789 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.65025697]\n",
      " [ 0.08264956 -1.18343728  0.55815055  0.13839656 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.619965  ]\n",
      " [ 0.9037135  -0.59376893  0.15310863 -1.03002898  1.29311536 -1.04757113\n",
      "  -0.86895727 -0.50834947]\n",
      " [-0.9958673   0.41177028  0.15310863  1.11160717 -0.86765522 -1.04757113\n",
      "  -0.86895727 -0.40942861]\n",
      " [-1.15993242 -0.96684975 -0.11691932 -1.03002898 -0.44509826 -1.04757113\n",
      "  -0.86895727 -0.3750503 ]\n",
      " [-0.03554419  1.15183144  0.01809466  1.43488428 -0.86765522  0.34440695\n",
      "  -0.69075673 -0.34197776]\n",
      " [-0.76124438 -2.94238594  0.01809466 -1.03002898 -0.86765522  0.34440695\n",
      "  -0.33435565 -0.24968869]\n",
      " [ 1.118048    1.07038088  0.55815055  0.8822505   1.44637892  0.34440695\n",
      "   0.37844651 -0.23044356]\n",
      " [ 0.07862666  0.12592138  0.55815055 -1.03002898 -0.86765522  0.34440695\n",
      "  -0.51255619 -0.14874583]\n",
      " [ 0.1160991  -0.51489465  0.2881226   1.14240568 -0.1807427   0.34440695\n",
      "  -0.15615511  0.0377352 ]\n",
      " [ 1.17509901  0.85993605  2.04330426  1.23266023  2.03887464  3.1283631\n",
      "   2.69505353  0.07872178]\n",
      " [-0.15936323  0.95303849  0.55815055  1.11787737 -0.1807427   0.34440695\n",
      "   0.55664705  0.07872178]\n",
      " [ 0.33747937 -0.30718329 -2.81719879 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.09851369]\n",
      " [-0.11017138 -0.14270309  0.8281785   0.8822505  -0.44509826 -1.04757113\n",
      "  -0.86895727  0.09851369]\n",
      " [-0.22010989  0.85561411  0.55815055 -1.03002898 -0.86765522  0.34440695\n",
      "   0.91304813  0.1553254 ]\n",
      " [-0.71399732  0.0110004   0.01809466  0.96483055  0.16402005  0.34440695\n",
      "   1.62585029  0.17943223]\n",
      " [ 0.66269388  1.15563954  0.55815055  1.15435171  1.16912805  0.34440695\n",
      "   0.55664705  0.18535613]\n",
      " [-0.07083973  1.52790617  0.2881226   1.40088236 -0.86765522  0.34440695\n",
      "  -0.33435565  0.2086566 ]\n",
      " [-0.75586358  0.31848951 -2.00711495  0.91647239 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.27503575]\n",
      " [-0.24626419  0.52151525 -0.38694727  0.82752319 -0.86765522  0.34440695\n",
      "   0.55664705  0.29086898]\n",
      " [-0.76124438  2.10127925  1.23322042  1.54225202 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.31663434]\n",
      " [ 0.55214455  0.21283185 -0.11691932  1.05246539  1.50170584  0.34440695\n",
      "   0.55664705  0.32673071]\n",
      " [ 1.2159132  -0.2441444   1.09820645 -1.03002898  1.24908762  3.1283631\n",
      "   2.51685299  0.32673071]\n",
      " [ 0.57385266  0.58546452  0.55815055  1.16609525  1.07914887  0.34440695\n",
      "   1.62585029  0.38496775]\n",
      " [-1.53197866  1.82921036  0.69316453 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727  0.42173538]\n",
      " [ 0.43842708 -0.08387821 -0.52196124 -1.03002898  1.07914887  0.34440695\n",
      "   1.26944921  0.46561391]\n",
      " [-0.11521787  0.46089542  0.69316453 -1.03002898  0.28936185  0.34440695\n",
      "  -0.15615511  0.50329884]\n",
      " [ 1.52756447 -0.85663082  0.55815055 -0.1050703   1.8689359   0.34440695\n",
      "   0.91304813  0.74816076]\n",
      " [ 0.56363872  1.88843646  1.09820645  1.40088236  0.48894996  0.34440695\n",
      "   1.26944921  0.79630031]\n",
      " [ 1.01288993  1.70306453  1.90829029  1.54225202 -0.86765522  0.34440695\n",
      "  -0.51255619  0.83354436]\n",
      " [ 1.10725223 -0.10984037  0.69316453 -1.03002898  1.98656829  0.34440695\n",
      "   1.62585029  0.85295798]\n",
      " [ 1.2190955   0.45577338 -0.11691932 -1.03002898  0.39606027  0.34440695\n",
      "   0.91304813  0.90097779]\n",
      " [ 0.10052143 -1.31058265  0.2881226   0.31819952  0.28936185  0.34440695\n",
      "   0.55664705  0.90356948]\n",
      " [ 0.99242046 -0.3646778  -0.92700316  0.23411435  1.80201365  0.34440695\n",
      "   1.26944921  0.91641341]\n",
      " [ 1.132233    0.49140008  0.15310863  0.7030969   1.38643629  3.1283631\n",
      "   1.62585029  0.95140024]\n",
      " [ 0.18109221  0.1899692  -0.52196124  1.10527971  0.71191882  0.34440695\n",
      "   0.20024597  0.96597463]\n",
      " [ 1.66548696 -0.25800887  0.01809466 -1.03002898  1.80201365  0.34440695\n",
      "   1.26944921  1.00368795]\n",
      " [ 0.57498003  0.24110046 -0.79198919  1.06605117 -0.86765522 -1.04757113\n",
      "  -0.86895727  1.04644915]\n",
      " [ 0.32548825 -0.60986946 -0.25193329 -1.03002898  0.34468877  0.34440695\n",
      "   0.20024597  1.07454209]\n",
      " [ 1.24310643  2.55541174  0.15310863 -1.03002898  1.90019713  0.34440695\n",
      "   1.26944921  1.31139383]\n",
      " [ 0.18109221  0.15525053  1.63826234  0.5790429   0.71191882  0.34440695\n",
      "   1.80405083  1.31945687]\n",
      " [ 1.61742159  1.10952004  0.55815055 -1.03002898 -0.86765522 -1.04757113\n",
      "  -0.86895727  1.3509826 ]\n",
      " [ 1.26244405  0.58060761  0.55815055 -1.03002898  1.07914887  0.34440695\n",
      "   1.26944921  1.66041493]\n",
      " [ 2.10739693  0.62873791 -2.68218482 -1.03002898  1.68826718  0.34440695\n",
      "   0.55664705  1.92104373]\n",
      " [ 1.3282669  -0.54612667 -1.60207303 -1.03002898  1.90019713  0.34440695\n",
      "  -0.51255619  2.32046525]\n",
      " [ 1.30704467  0.34014146  0.55815055  1.0100326   1.24908762  0.34440695\n",
      "   1.98225137  2.61164875]\n",
      " [ 1.80971922  0.81196061  0.55815055  0.23411435  2.21673517  0.34440695\n",
      "  -0.15615511  2.70345173]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-af75c218e0c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mnbclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mest_prior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mnbclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_inner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_inner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mclassifier_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    602\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[0;32m    603\u001b[0m                                        dtype=np.float64)\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "### OBS. method can not use X values < 0\n",
    "\n",
    "## Crossvalidation for Naive Bayes\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = np.empty((1,1)) # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "\n",
    "# Naive Bayes classifier parameters\n",
    "alpha = [1]         # additive parameter (e.g. Laplace correction), lgges til da log bliver taget i MultinormilNB\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner['K_KNN_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        print(X_train_inner) \n",
    "        for count, value in enumerate(alpha):\n",
    "            est_prior = True  # uniform prior (change to True to estimate prior from data)    \n",
    "                       \n",
    "            nbclassifier = MultinomialNB(alpha=alpha, fit_prior=est_prior);\n",
    "            nbclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(nbclassifier)\n",
    " \n",
    "            y_NB = nbclassifier.predict(X_test_inner);\n",
    "            errorNB_inner = 100*(y_NB!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['alpha_of_{0}'.format(value)].append(errorNB_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the alpha value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_alpha = alpha[top_count]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    nbclassifierOuter = MultinomialNB(alpha=optimal_alpha, fit_prior=est_prior); #Uses optimal_alpha, which was found in the inner CV loop\n",
    "    nbclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_NB_outer = nbclassifier.predict(X_test_outer);\n",
    "    errorNB_outer = 100*(y_NB_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorNB_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cross-validation error [%]')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a5bfe95c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure()\n",
    "boxplot([error_KNN, error_dct])\n",
    "xlabel('K-Nearest Neighbors   vs.   Decision Tree')\n",
    "ylabel('Cross-validation error [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method selected: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Re-estimate of the model on all data for a maximum depth of 12 \n",
    "\n",
    "# Fit decision tree classifier, Gini split criterion, maximum depth of 12 on all data\n",
    "dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=12) \n",
    "dtc.fit(X_classification, y_classification.ravel())\n",
    "\n",
    "# New data object\n",
    "new_data = np.array([1, 2, 4, -1, -1, 5, 0, -3]).reshape(1,-1) # Gives 0 - No SVI\n",
    "#new_data = np.array([1, 2, 4, -1, 2, 5, 0, -3]).reshape(1,-1) # Gives 1 - Yes SVI\n",
    "\n",
    "# Evalulate the decision tree for a new data object\n",
    "new_data_class = dtc.predict(new_data)[0]\n",
    "print(new_data_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCaVol' 'lWeight' 'Age' 'lBPH' 'lCP' 'Gleason' 'pgg45' 'lPSA']\n"
     ]
    }
   ],
   "source": [
    "print(attributeNames_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"625pt\" height=\"581pt\"\r\n",
       " viewBox=\"0.00 0.00 624.50 581.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 577)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-577 620.5,-577 620.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"440.5,-573 336.5,-573 336.5,-505 440.5,-505 440.5,-573\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"388.5\" y=\"-557.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCP &lt;= 1.416</text>\r\n",
       "<text text-anchor=\"middle\" x=\"388.5\" y=\"-542.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.339</text>\r\n",
       "<text text-anchor=\"middle\" x=\"388.5\" y=\"-527.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 97</text>\r\n",
       "<text text-anchor=\"middle\" x=\"388.5\" y=\"-512.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [76, 21]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379,-469 278,-469 278,-401 379,-401 379,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lPSA &lt;= 0.448</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.191</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 84</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [75, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M369.02,-504.884C363.99,-496.332 358.508,-487.013 353.248,-478.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"356.175,-476.144 348.088,-469.299 350.141,-479.693 356.175,-476.144\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"341.814\" y=\"-489.799\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"501.5,-469 397.5,-469 397.5,-401 501.5,-401 501.5,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCaVol &lt;= 1.05</text>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.142</text>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 12]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>0&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M408.305,-504.884C413.419,-496.332 418.992,-487.013 424.339,-478.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"427.457,-479.678 429.586,-469.299 421.449,-476.085 427.457,-479.678\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"435.684\" y=\"-489.844\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"260.5,-357.5 162.5,-357.5 162.5,-304.5 260.5,-304.5 260.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"211.5\" y=\"-342.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"211.5\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 66</text>\r\n",
       "<text text-anchor=\"middle\" x=\"211.5\" y=\"-312.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [66, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M290.513,-400.884C277.015,-389.116 261.849,-375.894 248.439,-364.203\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"250.611,-361.453 240.773,-357.52 246.011,-366.73 250.611,-361.453\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"380,-365 279,-365 279,-297 380,-297 380,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lBPH &lt;= 1.038</text>\r\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 18</text>\r\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.825,-400.884C328.904,-392.778 328.99,-383.982 329.074,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332.575,-375.333 329.174,-365.299 325.576,-375.265 332.575,-375.333\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"268.5,-261 158.5,-261 158.5,-193 268.5,-193 268.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCaVol &lt;= 1.105</text>\r\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.426</text>\r\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [4, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M291.838,-296.884C281.404,-287.709 269.965,-277.65 259.13,-268.123\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"261.191,-265.274 251.37,-261.299 256.568,-270.531 261.191,-265.274\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"378,-253.5 287,-253.5 287,-200.5 378,-200.5 378,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"332.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"332.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"332.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [5, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>3&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M330.474,-296.884C330.788,-286.216 331.137,-274.352 331.455,-263.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"334.954,-263.619 331.749,-253.52 327.957,-263.413 334.954,-263.619\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"209,-157 90,-157 90,-89 209,-89 209,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lWeight &lt;= &#45;1.115</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.219</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 8</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 7]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192.721,-192.884C187.3,-184.243 181.387,-174.819 175.723,-165.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.673,-163.91 170.394,-157.299 172.744,-167.63 178.673,-163.91\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"328,-157 227,-157 227,-89 328,-89 328,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lPSA &lt;= 1.506</text>\r\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.48</text>\r\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>4&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.279,-192.884C239.7,-184.243 245.613,-174.819 251.277,-165.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.256,-167.63 256.606,-157.299 248.327,-163.91 254.256,-167.63\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91,-53 0,-53 0,-0 91,-0 91,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.126,-88.9485C102.857,-79.6175 91.6916,-69.4722 81.4478,-60.1641\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.5788,-57.3713 73.824,-53.2367 78.8713,-62.5521 83.5788,-57.3713\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"200,-53 109,-53 109,-0 200,-0 200,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 7</text>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 7]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>5&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.249,-88.9485C151.684,-80.7153 152.154,-71.848 152.596,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.105,-63.4077 153.138,-53.2367 149.115,-63.0378 156.105,-63.4077\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"314,-53 223,-53 223,-0 314,-0 314,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"268.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"268.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"268.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M274.352,-88.9485C273.559,-80.6238 272.705,-71.6509 271.9,-63.2027\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.384,-62.8598 270.951,-53.2367 268.415,-63.5235 275.384,-62.8598\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"423,-53 332,-53 332,-0 423,-0 423,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"377.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"377.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"377.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.475,-88.9485C322.349,-79.6175 333.085,-69.4722 342.935,-60.1641\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"345.401,-62.649 350.265,-53.2367 340.593,-57.5613 345.401,-62.649\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"500,-365 399,-365 399,-297 500,-297 500,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lPSA &lt;= 0.634</text>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M449.5,-400.884C449.5,-392.778 449.5,-383.982 449.5,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"453,-375.299 449.5,-365.299 446,-375.299 453,-375.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"616.5,-357.5 518.5,-357.5 518.5,-304.5 616.5,-304.5 616.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"567.5\" y=\"-342.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567.5\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567.5\" y=\"-312.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 10]</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>12&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M487.811,-400.884C501.425,-389.116 516.721,-375.894 530.245,-364.203\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"532.7,-366.707 537.977,-357.52 528.123,-361.412 532.7,-366.707\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"492,-253.5 401,-253.5 401,-200.5 492,-200.5 492,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"446.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"446.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"446.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>13&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M448.526,-296.884C448.212,-286.216 447.863,-274.352 447.545,-263.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"451.043,-263.413 447.251,-253.52 444.046,-263.619 451.043,-263.413\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601,-253.5 510,-253.5 510,-200.5 601,-200.5 601,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"555.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"555.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"555.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>13&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M483.915,-296.884C496.03,-285.226 509.628,-272.141 521.693,-260.532\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"524.2,-262.976 528.979,-253.52 519.347,-257.932 524.2,-262.976\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x2a5bfc73710>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export tree graph for visualization purposes:\n",
    "# (note: you can use i.e. Graphviz application to visualize the file)\n",
    "out = tree.export_graphviz(dtc, out_file='tree_gini.gvz', feature_names=attributeNames_classification)\n",
    "#graphviz.render('dot','png','tree_gini',quiet=False)\n",
    "src=graphviz.Source.from_file('tree_gini.gvz')\n",
    "## Comment in to automatically open pdf\n",
    "## Note. If you get an error (e.g. exit status 1), try closing the pdf file/viewer\n",
    "#src.render('../tree_gini', view=True)\n",
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "# zero rule algorithm for classification\n",
    "def Baseline_model(y_train, y_test):\n",
    "    prediction = stats.mode(y_train)[0]\n",
    "    predicted = [int(prediction) for i in range(len(y_test))]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-level-cross validation for dtc, KNN and baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[21.0, 19.75, 19.666666666666668, 20.916666666666668, 22.166666666666668, 20.916666666666668, 20.916666666666668, 22.25, 24.75, 22.25, 22.25, 20.916666666666668, 20.916666666666668, 22.166666666666668, 20.916666666666668, 23.5, 23.5, 22.166666666666668, 20.916666666666668]\n",
      "The index of optimal tc value is: 2\n",
      "The optimal tc value across inner CV folds is: 4\n",
      "Errors for each outer tc fold: [15.0]\n",
      "Inner_error_values are:[18.25, 17.083333333333332, 10.5, 15.75, 15.833333333333334, 15.75, 13.083333333333334, 17.0, 11.833333333333334, 15.75, 14.416666666666666, 18.25, 18.25, 16.916666666666668, 19.5, 16.916666666666668, 16.916666666666668, 16.916666666666668, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25, 18.25]\n",
      "The index of optimal KNN value is: 2\n",
      "The optimal KNN value across inner CV folds is: 3\n",
      "Errors for each outer CV fold: [15.0]\n",
      "Errors for baseline outer fold[35.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[12.916666666666668, 15.583333333333334, 16.916666666666668, 14.166666666666668, 14.25, 15.5, 16.833333333333332, 14.25, 16.833333333333332, 16.75, 15.5, 15.5, 12.916666666666668, 15.583333333333334, 14.083333333333334, 14.25, 14.25, 14.166666666666666, 15.5]\n",
      "The index of optimal tc value is: 2\n",
      "The optimal tc value across inner CV folds is: 2\n",
      "Errors for each outer tc fold: [15.0, 5.0]\n",
      "Inner_error_values are:[19.5, 19.25, 18.083333333333332, 16.75, 15.5, 16.833333333333332, 14.166666666666666, 14.166666666666666, 12.833333333333334, 12.916666666666668, 11.583333333333334, 14.25, 14.166666666666668, 15.5, 15.5, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 21.916666666666668, 20.583333333333332, 21.833333333333332, 21.833333333333332, 20.583333333333332, 20.583333333333332, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668]\n",
      "The index of optimal KNN value is: 2\n",
      "The optimal KNN value across inner CV folds is: 11\n",
      "Errors for each outer CV fold: [15.0, 10.0]\n",
      "Errors for baseline outer fold[35.0, 20.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[19.416666666666668, 19.333333333333336, 21.833333333333336, 23.166666666666668, 21.916666666666668, 24.416666666666668, 23.25, 24.5, 23.166666666666668, 21.833333333333336, 23.083333333333336, 21.833333333333336, 21.833333333333336, 21.916666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668, 20.583333333333336, 21.833333333333336]\n",
      "The index of optimal tc value is: 2\n",
      "The optimal tc value across inner CV folds is: 3\n",
      "Errors for each outer tc fold: [15.0, 5.0, 10.526315789473685]\n",
      "Inner_error_values are:[20.583333333333336, 20.583333333333332, 19.416666666666668, 22.0, 21.916666666666668, 19.416666666666668, 20.75, 18.166666666666668, 16.833333333333336, 18.083333333333332, 16.833333333333332, 15.583333333333334, 16.833333333333332, 16.833333333333332, 15.583333333333334, 15.583333333333334, 15.583333333333334, 18.083333333333332, 16.833333333333332, 20.583333333333332, 20.583333333333332, 21.916666666666668, 21.916666666666668, 24.416666666666668, 23.166666666666668, 23.166666666666668, 24.416666666666668, 24.416666666666668, 24.416666666666668, 24.416666666666668, 25.666666666666668, 24.416666666666668, 24.416666666666668, 23.166666666666668, 23.166666666666668, 24.416666666666668, 24.416666666666668, 24.416666666666668, 24.416666666666668, 24.416666666666668]\n",
      "The index of optimal KNN value is: 2\n",
      "The optimal KNN value across inner CV folds is: 12\n",
      "Errors for each outer CV fold: [15.0, 10.0, 5.2631578947368425]\n",
      "Errors for baseline outer fold[35.0, 20.0, 10.526315789473685]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[16.583333333333332, 15.333333333333334, 13.916666666666666, 14.0, 12.666666666666666, 15.333333333333334, 13.916666666666666, 12.666666666666666, 14.0, 14.0, 12.666666666666666, 12.666666666666666, 14.0, 16.583333333333332, 15.25, 13.916666666666666, 15.25, 16.583333333333332, 15.25]\n",
      "The index of optimal tc value is: 2\n",
      "The optimal tc value across inner CV folds is: 6\n",
      "Errors for each outer tc fold: [15.0, 5.0, 10.526315789473685, 15.789473684210526]\n",
      "Inner_error_values are:[15.25, 14.0, 12.75, 10.166666666666666, 11.416666666666666, 11.5, 11.416666666666666, 11.416666666666666, 10.083333333333334, 11.416666666666666, 10.083333333333334, 11.416666666666666, 11.416666666666666, 12.75, 12.75, 16.583333333333332, 15.333333333333334, 15.416666666666668, 16.666666666666668, 17.916666666666668, 17.916666666666668, 18.0, 16.666666666666668, 18.0, 18.0, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25]\n",
      "The index of optimal KNN value is: 2\n",
      "The optimal KNN value across inner CV folds is: 9\n",
      "Errors for each outer CV fold: [15.0, 10.0, 5.2631578947368425, 21.05263157894737]\n",
      "Errors for baseline outer fold[35.0, 20.0, 10.526315789473685, 31.57894736842105]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[13.916666666666666, 16.583333333333332, 15.25, 15.333333333333334, 17.916666666666668, 17.916666666666668, 16.583333333333332, 15.333333333333334, 16.666666666666668, 17.916666666666668, 16.666666666666668, 16.583333333333332, 17.916666666666668, 17.916666666666668, 17.916666666666668, 16.666666666666668, 16.583333333333332, 16.666666666666668, 15.333333333333334]\n",
      "The index of optimal tc value is: 2\n",
      "The optimal tc value across inner CV folds is: 2\n",
      "Errors for each outer tc fold: [15.0, 5.0, 10.526315789473685, 15.789473684210526, 10.526315789473685]\n",
      "Inner_error_values are:[17.916666666666668, 17.916666666666668, 12.666666666666666, 12.75, 12.666666666666666, 11.416666666666666, 13.916666666666666, 12.75, 15.166666666666666, 13.916666666666666, 13.916666666666666, 15.166666666666666, 15.166666666666666, 15.25, 15.25, 15.25, 15.25, 15.25, 15.25, 12.75, 12.75, 12.75, 11.5, 15.25, 15.25, 17.75, 17.75, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 23.0, 23.0, 24.25, 24.25, 24.25, 24.25, 24.25, 24.25, 24.25]\n",
      "The index of optimal KNN value is: 2\n",
      "The optimal KNN value across inner CV folds is: 6\n",
      "Errors for each outer CV fold: [15.0, 10.0, 5.2631578947368425, 21.05263157894737, 15.789473684210526]\n",
      "Errors for baseline outer fold[35.0, 20.0, 10.526315789473685, 31.57894736842105, 10.526315789473685]\n"
     ]
    }
   ],
   "source": [
    "# Results from the 2-level cross-validation for dtc \n",
    "# Errors for each outer tc fold: [15.0, 30.0, 10.526315789473685, 10.526315789473685, 15.789473684210526]\n",
    "# The errors for the best performing models are: 10.526315789473685, 15.0\n",
    "## Crossvalidation for decision trees\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# dtc\n",
    "index_min_lst_dtc = []\n",
    "min_indices_dtc = []\n",
    "error_outer_dtc = [] # List for the errors in outer CV fold\n",
    "dict_inner_dtc = {}\n",
    "error_inner_dtc = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "# Tree complexity parameter - constraint on maximum depth\n",
    "tc = np.arange(2, 21, 1)\n",
    "classifier_lst_dtc = []\n",
    "\n",
    "for count, value in enumerate(tc):\n",
    "    error_inner_dtc['tc_of_{0}'.format(value)] = []\n",
    "\n",
    "# KNN\n",
    "index_min_lst_KNN = []\n",
    "min_indices_KNN = []\n",
    "error_outer_KNN = [] # List for the errors in outer CV fold\n",
    "dict_inner_KNN = {}\n",
    "error_inner_KNN = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "K_KNN = range(1,41) # Change here for different nearest neighbour crossvalidation - test of K=1-40\n",
    "classifier_lst_KNN = []\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner_KNN['K_KNN_of_{0}'.format(value)] = []\n",
    "    \n",
    "# Baseline model\n",
    "error_baseline = []\n",
    "\n",
    "\n",
    "\n",
    "k=0\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "    # Decision tree classifier\n",
    "        for count, value in enumerate(tc):\n",
    "            dist=1\n",
    "            \n",
    "            # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "            dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=value) \n",
    "            dtc.fit(X_train_inner, y_train_inner.ravel());\n",
    "            classifier_lst_dtc.append(dtc)\n",
    "            \n",
    "            y_dtc = dtc.predict(X_test_inner);\n",
    "            errordtc_inner = 100*(y_dtc!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner_dtc['tc_of_{0}'.format(value)].append(errordtc_inner) # add errors for each fold to each model\n",
    "    \n",
    "    # KNN classifier\n",
    "            for count, value in enumerate(K_KNN):\n",
    "                dist=2 # euclidean_distance\n",
    "                       \n",
    "                knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "                knclassifier.fit(X_train_inner, y_train_inner);\n",
    "                classifier_lst_KNN.append(knclassifier)\n",
    "            \n",
    "                y_KNN = knclassifier.predict(X_test_inner);\n",
    "                errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "                #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "                error_inner_KNN['K_KNN_of_{0}'.format(value)].append(errorKNN_inner) # add errors for each fold to each model\n",
    "        \n",
    "        \n",
    "        kk += 1\n",
    "    #dtc\n",
    "    # Find the dtc value with minimum average error value\n",
    "    for key in error_inner_dtc.keys():\n",
    "        index_min_lst_dtc.append(mean(error_inner_dtc[key]))\n",
    "        \n",
    "    print('Inner_error_values_ for dtc are:' + str(index_min_lst_dtc))\n",
    "    index_min_dtc = np.argmin(index_min_lst_dtc) #Find the index of the minimum error value\n",
    "    top_count_dtc = index_min_dtc\n",
    "    min_indices_dtc.append(index_min_dtc) \n",
    "        \n",
    "    index_min_lst_dtc = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner_dtc.keys():\n",
    "        error_inner_dtc[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal tc value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_tc = tc[top_count_dtc]\n",
    "    \n",
    "    print('The optimal tc value across inner CV folds is: ' + str(optimal_tc))\n",
    "    \n",
    "    \n",
    "    dtcclassifierOuter = tree.DecisionTreeClassifier(criterion='gini', max_depth=optimal_tc);  #Uses optimal_tc, which was found in the inner CV loop\n",
    "    dtcclassifierOuter.fit(X_train_outer, y_train_outer.ravel());\n",
    "            \n",
    "    y_dtc_outer = dtcclassifierOuter.predict(X_test_outer);\n",
    "    errordtc_outer = 100*(y_dtc_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer_dtc.append(errordtc_outer)\n",
    "    print('Errors for each outer tc fold: ' + str(error_outer_dtc))\n",
    "    \n",
    "    \n",
    "    # KNN\n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner_KNN.keys():\n",
    "        index_min_lst_KNN.append(mean(error_inner_KNN[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst_KNN))\n",
    "    index_min_KNN = np.argmin(index_min_lst_KNN) #Find the index of the minimum error value\n",
    "    top_count_KNN = index_min_KNN\n",
    "    min_indices_KNN.append(index_min_KNN) \n",
    "        \n",
    "    index_min_lst_KNN = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner_KNN.keys():\n",
    "        error_inner_KNN[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_K = K_KNN[top_count_KNN]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifierOuter.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer_KNN.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer_KNN))\n",
    " \n",
    "    \n",
    "    \n",
    "    # Fit baseline model\n",
    "            \n",
    "    y_baselinemodel = Baseline_model(y_train_outer, y_test_outer);\n",
    "    error_baseline_outer = 100*(y_baselinemodel!=y_test_outer).sum().astype(float)/len(y_test_outer)  \n",
    "    error_baseline.append(error_baseline_outer)\n",
    "    print('Errors for baseline outer fold'+str(error_baseline))\n",
    "\n",
    "error_dct = error_outer_dtc\n",
    "error_KNN = error_outer_KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1340206185567\n",
      "13.144329896907216\n"
     ]
    }
   ],
   "source": [
    "# Final generalization error for DCT\n",
    "DTC_error = (len(y_test_outer)/N*np.mat(error_dct)).sum()\n",
    "print(DTC_error)\n",
    "# Final generalization error for KNN\n",
    "KNN_error = (len(y_test_outer)/N*np.mat(error_KNN)).sum()\n",
    "print(KNN_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer error dct is[15.0, 5.0, 10.526315789473685, 15.789473684210526, 10.526315789473685]\n",
      "Outer error of KNN is[15.0, 10.0, 5.2631578947368425, 21.05263157894737, 15.789473684210526]\n",
      "Outer error of baseline_model is[35.0, 20.0, 10.526315789473685, 31.57894736842105, 10.526315789473685]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cross-validation error [%]')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a5c6510f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The two best performing models are from dct\n",
    "print('Outer error dct is' + str(error_dct))\n",
    "print('Outer error of KNN is' + str(error_KNN))\n",
    "print('Outer error of baseline_model is' + str(error_baseline))\n",
    "\n",
    "figure()\n",
    "boxplot([error_KNN, error_dct])\n",
    "xlabel('K-Nearest Neighbors   vs.   Decision Tree')\n",
    "ylabel('Cross-validation error [%]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 10\n",
      "CV-fold 2 of 10\n",
      "CV-fold 3 of 10\n",
      "CV-fold 4 of 10\n",
      "CV-fold 5 of 10\n",
      "CV-fold 6 of 10\n",
      "CV-fold 7 of 10\n",
      "CV-fold 8 of 10\n",
      "CV-fold 9 of 10\n",
      "CV-fold 10 of 10\n",
      "Model 1 and baseline model are significantly different.\n",
      "20.674506993717365\n",
      "48.43660411739375\n",
      "Baseline model and Model 2 are significantly different.\n",
      "31.97642597819574\n",
      "49.13468513291537\n",
      "Model 1 and Model 2 are not significantly different\n",
      "-1.86138429702791\n",
      "13.861384297027907\n"
     ]
    }
   ],
   "source": [
    "# The best performing classifiers are KNN with K = 2 and a dtc with tc=10\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# Initialize variables\n",
    "Error_base_line = np.empty((K,1))\n",
    "Error_model_1 = np.empty((K,1))\n",
    "Error_model_2 = np.empty((K,1))\n",
    "\n",
    "n_tested=0\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K))\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # Fit and evaluate KNN\n",
    "    model1 = KNeighborsClassifier(n_neighbors=2, p=dist);\n",
    "    model1 = model1.fit(X_train, y_train)\n",
    "    y_model1 = model1.predict(X_test)\n",
    "    Error_model_1[k] = 100*(y_model1!=y_test).sum().astype(float)/len(y_test)\n",
    "    \n",
    "    # Fit and evaluate Decision Tree classifier\n",
    "    model2 = tree.DecisionTreeClassifier(criterion='gini', max_depth=10);\n",
    "    model2 = model2.fit(X_train, y_train.ravel())\n",
    "    y_model2 = model2.predict(X_test)\n",
    "    Error_model_2[k] = 100*(y_model2!=y_test).sum().astype(float)/len(y_test)  \n",
    "    \n",
    "    # Fit and evaluate baseline model classifier\n",
    "    y_baseline = Baseline_model(y_train, y_test);\n",
    "    Error_base_line[k] = 100*(y_baseline!=y_test).sum().astype(float)/len(y_test)\n",
    "  \n",
    "    k+=1\n",
    "\n",
    "# Comparison of Baseline model with model 1\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_1)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of Baseline model with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Baseline model and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Baseline model and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of model 1 with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_model_1-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gammel kode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3592b79c6b59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mzb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#nu = K-1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0msig\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mzb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "Error_base_line = min(error_baseline)\n",
    "Error_model_1 = min(error_dct) # Gives the best performing model\n",
    "Error_model_2 = sorted(error_dct)[1] # Gives the second best performing model\n",
    "\n",
    "# Comparison of Baseline model with model 1\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_1)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of Baseline model with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 2 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 2 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of model 1 with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_model_1-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two level cross validation for KNN - Greta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579, 15.789473684210526]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579, 15.789473684210526, 15.789473684210526]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K_outer,1))\n",
    "#Error_KNN_inner = np.empty((K_inner,3))\n",
    "#Error_NaveB = np.empty((K_outer,1))\n",
    "#n_tested=0\n",
    "\n",
    "K_KNN = [1, 2, 3] # Change here for different nearest neighbour crossvalidation\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            \n",
    "        # Find the KNN value with least error value\n",
    "        index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "        min_indices.append(index_min) \n",
    "        \n",
    "        index_min_lst = [] # Clear for next CV fold\n",
    "        \n",
    "        kk += 1\n",
    "\n",
    "        counts = np.bincount(min_indices) # Count which index appears the maximum number of times = i.e. the must be the least error value\n",
    "        top_count = np.argmax(counts)\n",
    "        # Only use the count from the last iteration! \n",
    "        optimal_K = K_KNN[top_count]\n",
    "        \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "\n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "[15.0, 35.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "[15.0, 35.0, 10.526315789473685]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4, 0, 29, 24, 8, 13]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0, 35.0, 10.526315789473685, 26.31578947368421]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4, 0, 29, 24, 8, 13, 1, 12, 3, 13, 0]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0, 35.0, 10.526315789473685, 26.31578947368421, 21.05263157894737]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "errorKNN_inner_GT=[]\n",
    "errorKNN_outer_GT = []\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = []\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K_outer,1))\n",
    "#Error_KNN_inner = np.empty((K_inner,3))\n",
    "#Error_NaveB = np.empty((K_outer,1))\n",
    "#n_tested=0\n",
    "\n",
    "K_KNN = range(1,41)\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner_GT = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            index_min_lst.append(errorKNN_inner_GT) #Append the error values to a list\n",
    "            \n",
    "        # Find the KNN value with least error value\n",
    "        index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "        min_indices.append(index_min) \n",
    "        \n",
    "        index_min_lst = [] # Clear for next CV fold\n",
    "        \n",
    "        kk += 1\n",
    "\n",
    "    print(min_indices)\n",
    "    counts = np.bincount(min_indices) # Count which index appears the maximum number of times = i.e. the must be the least error value\n",
    "    top_count = np.argmax(counts)\n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    # Only use the count from the last iteration! \n",
    "    optimal_K = K_KNN[top_count]\n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=1, p=dist);\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer_GT = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer_GT)\n",
    "    print(error_outer)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
